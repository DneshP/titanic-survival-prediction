{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":3136,"databundleVersionId":26502,"sourceType":"competition"}],"dockerImageVersionId":30587,"isInternetEnabled":false,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# The goal is to predict which passengers survived the Titanic shipwreck.\n\n## Variable Notes\n\n- **pclass:** A proxy for socio-economic status (SES)\n  - 1st = Upper\n  - 2nd = Middle\n  - 3rd = Lower\n\n- **age:** Age is fractional if less than 1. If the age is estimated, it is in the form of xx.5.\n\n- **sibsp:** The dataset defines family relations in this way...\n  - Sibling = brother, sister, stepbrother, stepsister\n  - Spouse = husband, wife (mistresses and fianc√©s were ignored)\n\n- **parch:** The dataset defines family relations in this way...\n  - Parent = mother, father\n  - Child = daughter, son, stepdaughter, stepson\n  - Some children traveled only with a nanny, therefore parch=0 for them.\n","metadata":{}},{"cell_type":"code","source":"# Let's take a look at the data\n\nimport pandas as pd\n\nfile_path = '/kaggle/input/titanic/train.csv'\n\n# Load the CSV file into a Pandas DataFrame\ndf = pd.read_csv(file_path)\n\n# Display the first few rows of the DataFrame to inspect the data\nprint(df.head(10))","metadata":{"execution":{"iopub.status.busy":"2023-11-17T17:19:46.134718Z","iopub.execute_input":"2023-11-17T17:19:46.135297Z","iopub.status.idle":"2023-11-17T17:19:46.687919Z","shell.execute_reply.started":"2023-11-17T17:19:46.135244Z","shell.execute_reply":"2023-11-17T17:19:46.686693Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"   PassengerId  Survived  Pclass  \\\n0            1         0       3   \n1            2         1       1   \n2            3         1       3   \n3            4         1       1   \n4            5         0       3   \n5            6         0       3   \n6            7         0       1   \n7            8         0       3   \n8            9         1       3   \n9           10         1       2   \n\n                                                Name     Sex   Age  SibSp  \\\n0                            Braund, Mr. Owen Harris    male  22.0      1   \n1  Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0      1   \n2                             Heikkinen, Miss. Laina  female  26.0      0   \n3       Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0      1   \n4                           Allen, Mr. William Henry    male  35.0      0   \n5                                   Moran, Mr. James    male   NaN      0   \n6                            McCarthy, Mr. Timothy J    male  54.0      0   \n7                     Palsson, Master. Gosta Leonard    male   2.0      3   \n8  Johnson, Mrs. Oscar W (Elisabeth Vilhelmina Berg)  female  27.0      0   \n9                Nasser, Mrs. Nicholas (Adele Achem)  female  14.0      1   \n\n   Parch            Ticket     Fare Cabin Embarked  \n0      0         A/5 21171   7.2500   NaN        S  \n1      0          PC 17599  71.2833   C85        C  \n2      0  STON/O2. 3101282   7.9250   NaN        S  \n3      0            113803  53.1000  C123        S  \n4      0            373450   8.0500   NaN        S  \n5      0            330877   8.4583   NaN        Q  \n6      0             17463  51.8625   E46        S  \n7      1            349909  21.0750   NaN        S  \n8      2            347742  11.1333   NaN        S  \n9      0            237736  30.0708   NaN        C  \n","output_type":"stream"}]},{"cell_type":"code","source":"df.info()\n# identify missing values\nmissing_column_values_df = df.loc[:, df.isnull().any()]\nprint(missing_column_values_df.columns, \"\\n\", missing_column_values_df.dtypes)","metadata":{"execution":{"iopub.status.busy":"2023-11-17T17:19:46.690390Z","iopub.execute_input":"2023-11-17T17:19:46.690841Z","iopub.status.idle":"2023-11-17T17:19:46.735908Z","shell.execute_reply.started":"2023-11-17T17:19:46.690801Z","shell.execute_reply":"2023-11-17T17:19:46.734587Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stdout","text":"<class 'pandas.core.frame.DataFrame'>\nRangeIndex: 891 entries, 0 to 890\nData columns (total 12 columns):\n #   Column       Non-Null Count  Dtype  \n---  ------       --------------  -----  \n 0   PassengerId  891 non-null    int64  \n 1   Survived     891 non-null    int64  \n 2   Pclass       891 non-null    int64  \n 3   Name         891 non-null    object \n 4   Sex          891 non-null    object \n 5   Age          714 non-null    float64\n 6   SibSp        891 non-null    int64  \n 7   Parch        891 non-null    int64  \n 8   Ticket       891 non-null    object \n 9   Fare         891 non-null    float64\n 10  Cabin        204 non-null    object \n 11  Embarked     889 non-null    object \ndtypes: float64(2), int64(5), object(5)\nmemory usage: 83.7+ KB\nIndex(['Age', 'Cabin', 'Embarked'], dtype='object') \n Age         float64\nCabin        object\nEmbarked     object\ndtype: object\n","output_type":"stream"}]},{"cell_type":"code","source":"df[\"Dependents\"] = df[\"SibSp\"] + df[\"Parch\"]\n\nprint(f'Passengers who travelled without family members: {df[df[\"Dependents\"] == 0].shape[0]}')\nprint(f'Passengers who travelled with family members: {df[df[\"Dependents\"] > 0].shape[0]}')","metadata":{"execution":{"iopub.status.busy":"2023-11-17T17:19:46.738301Z","iopub.execute_input":"2023-11-17T17:19:46.739319Z","iopub.status.idle":"2023-11-17T17:19:46.756829Z","shell.execute_reply.started":"2023-11-17T17:19:46.739260Z","shell.execute_reply":"2023-11-17T17:19:46.755171Z"},"trusted":true},"execution_count":3,"outputs":[{"name":"stdout","text":"Passengers who travelled without family members: 537\nPassengers who travelled with family members: 354\n","output_type":"stream"}]},{"cell_type":"code","source":"# Calculate the percentage of male and female passengers\nmale_percentage = (df['Sex'] == 'male').sum() / len(df) * 100\nfemale_percentage = (df['Sex'] == 'female').sum() / len(df) * 100\n\n# Display the percentages\nprint(f\"Percentage of male passengers: {male_percentage:.2f}%\")\nprint(f\"Percentage of female passengers: {female_percentage:.2f}%\")\n","metadata":{"execution":{"iopub.status.busy":"2023-11-17T17:46:40.265969Z","iopub.execute_input":"2023-11-17T17:46:40.267467Z","iopub.status.idle":"2023-11-17T17:46:40.277459Z","shell.execute_reply.started":"2023-11-17T17:46:40.267409Z","shell.execute_reply":"2023-11-17T17:46:40.276302Z"},"trusted":true},"execution_count":29,"outputs":[{"name":"stdout","text":"Percentage of male passengers: 64.76%\nPercentage of female passengers: 35.24%\n","output_type":"stream"}]},{"cell_type":"code","source":"# Split the dataset\nfrom sklearn.model_selection import train_test_split\n\n# Define features (X) and target variable (y)\nX = df.drop('Survived', axis=1)\ny = df['Survived']\n\n# Split the data into training and testing sets with stratification\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=df['Sex'])\n","metadata":{"execution":{"iopub.status.busy":"2023-11-17T17:45:03.307209Z","iopub.execute_input":"2023-11-17T17:45:03.307819Z","iopub.status.idle":"2023-11-17T17:45:03.327837Z","shell.execute_reply.started":"2023-11-17T17:45:03.307767Z","shell.execute_reply":"2023-11-17T17:45:03.326300Z"},"trusted":true},"execution_count":27,"outputs":[]},{"cell_type":"code","source":"# Calculate the percentage of male and female passengers\nmale_percentage_train = (X_train['Sex'] == 'male').sum() / len(X_train) * 100\nfemale_percentage_train = (X_train['Sex'] == 'female').sum() / len(X_train) * 100\n\nmale_percentage_test = (X_train['Sex'] == 'male').sum() / len(X_train) * 100\nfemale_percentage_test = (X_train['Sex'] == 'female').sum() / len(X_train) * 100\n\n# Display the percentages\nprint(f\"Percentage of male passengers train: {male_percentage_train:.2f}%\")\nprint(f\"Percentage of female passengers train: {female_percentage_train:.2f}%\")\nprint(f\"Percentage of male passengers test: {male_percentage_test:.2f}%\")\nprint(f\"Percentage of female passengers test: {female_percentage_test:.2f}%\")\n","metadata":{"execution":{"iopub.status.busy":"2023-11-17T17:47:01.886971Z","iopub.execute_input":"2023-11-17T17:47:01.887471Z","iopub.status.idle":"2023-11-17T17:47:01.900139Z","shell.execute_reply.started":"2023-11-17T17:47:01.887435Z","shell.execute_reply":"2023-11-17T17:47:01.898703Z"},"trusted":true},"execution_count":30,"outputs":[{"name":"stdout","text":"Percentage of male passengers train: 64.75%\nPercentage of female passengers train: 35.25%\nPercentage of male passengers test: 64.75%\nPercentage of female passengers test: 35.25%\n","output_type":"stream"}]},{"cell_type":"code","source":"# preprocesing pipeline\n\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.compose import make_column_selector, make_column_transformer\nfrom sklearn.impute import SimpleImputer\nfrom sklearn.preprocessing import StandardScaler, OneHotEncoder, FunctionTransformer\nimport numpy as np\n\n# Define the features and target column\nfeatures = df.columns[df.columns != 'Survived']\ntarget = 'Survived'\n\nnum_features = make_column_selector(dtype_include=np.number)(df[features])\ncat_features = make_column_selector(dtype_include=object)(df[features])\n\n\nnum_pipeline = Pipeline([\n    (\"impute\", SimpleImputer(strategy=\"median\")),\n    (\"standardize\", StandardScaler()),\n])\n\ncat_pipeline = Pipeline([\n    (\"impute\", SimpleImputer(strategy=\"most_frequent\")),\n    (\"one_hot_encode\", OneHotEncoder(handle_unknown=\"ignore\"))\n])\n\npreprocessing = make_column_transformer(\n    (num_pipeline, num_features),\n    (cat_pipeline, cat_features),\n)","metadata":{"execution":{"iopub.status.busy":"2023-11-17T17:31:09.571860Z","iopub.execute_input":"2023-11-17T17:31:09.572411Z","iopub.status.idle":"2023-11-17T17:31:09.588194Z","shell.execute_reply.started":"2023-11-17T17:31:09.572371Z","shell.execute_reply":"2023-11-17T17:31:09.586801Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"code","source":"df_processed = preprocessing.fit_transform(df)","metadata":{"execution":{"iopub.status.busy":"2023-11-17T17:48:10.703572Z","iopub.execute_input":"2023-11-17T17:48:10.704048Z","iopub.status.idle":"2023-11-17T17:48:10.741128Z","shell.execute_reply.started":"2023-11-17T17:48:10.704008Z","shell.execute_reply":"2023-11-17T17:48:10.739646Z"},"trusted":true},"execution_count":34,"outputs":[]},{"cell_type":"code","source":"print(df_processed.shape)\nprint(df.shape)","metadata":{"execution":{"iopub.status.busy":"2023-11-17T17:48:12.106450Z","iopub.execute_input":"2023-11-17T17:48:12.107773Z","iopub.status.idle":"2023-11-17T17:48:12.113182Z","shell.execute_reply.started":"2023-11-17T17:48:12.107720Z","shell.execute_reply":"2023-11-17T17:48:12.112360Z"},"trusted":true},"execution_count":35,"outputs":[{"name":"stdout","text":"(891, 1731)\n(891, 13)\n","output_type":"stream"}]},{"cell_type":"markdown","source":"# Correlation Summary\n\nThe correlation matrix provides insights into the relationships between different features and the target variable 'Survived'. Here are some key correlations:\n\n### Positive Correlations with Survival:\n\n- Being Female (pipeline-2__Sex_female): 0.692025\n  - This suggests a strong positive correlation between being female and survival. Female passengers were more likely to survive.\n\n- Higher Fare (pipeline-1__Fare): 0.414994\n  - Passengers who paid higher fares had a positive correlation with survival, indicating a potential association between fare and survival.\n\n- Embarked at Cherbourg (pipeline-2__Embarked_C): 0.286461\n  - Passengers who embarked at Cherbourg had a positive correlation with survival.\n\n### Negative Correlations with Survival:\n\n- Lower Passenger Class (pipeline-1__Pclass): -0.472895\n  - There is a negative correlation with passenger class, indicating that lower-class passengers were less likely to survive.\n\n- Being Male (pipeline-2__Sex_male): -0.692025\n  - This strong negative correlation suggests that being male is associated with a lower likelihood of survival.\n\n### Other Correlations:\n\n- Parch (pipeline-1__Parch): 0.163889\n  - A positive correlation with survival, but not as strong as being female or having a higher fare.\n\n- Embarked at Southampton (pipeline-2__Embarked_S): -0.244726\n  - Negative correlation with survival. Passengers who embarked at Southampton had a lower chance of survival.\n\n- Cabin B96 B98 (pipeline-2__Cabin_B96 B98): -0.460145\n  - Negative correlation with survival. Passengers with this cabin had a lower likelihood of survival.\n\n- Ticket 3101295 (pipeline-2__Ticket_3101295): -0.093152\n  - Negative correlation with survival, but not as strong.\n\nThese correlations provide valuable insights into the factors influencing survival on the Titanic.\n","metadata":{}},{"cell_type":"code","source":"# Convert the sparse matrix to a dense Pandas DataFrame with correct column names\ndf_processed_dense = pd.DataFrame(df_processed.toarray(), columns=preprocessing.get_feature_names_out())\n\n# Add the 'Survived' column to the processed DataFrame\ndf_processed_dense['Survived'] = df['Survived']\n\n# Compute the correlation matrix for the processed data\ncorr_matrix_processed = df_processed_dense.corr()\n\n# Coorelation\ncorr_matrix = corr_matrix_processed.corr(numeric_only=True)\ncorr_matrix[\"Survived\"].sort_values(ascending=False)\n","metadata":{"execution":{"iopub.status.busy":"2023-11-17T17:48:14.518184Z","iopub.execute_input":"2023-11-17T17:48:14.518612Z","iopub.status.idle":"2023-11-17T17:48:35.937288Z","shell.execute_reply.started":"2023-11-17T17:48:14.518579Z","shell.execute_reply":"2023-11-17T17:48:35.935968Z"},"trusted":true},"execution_count":36,"outputs":[{"execution_count":36,"output_type":"execute_result","data":{"text/plain":"Survived                      1.000000\npipeline-2__Sex_female        0.692025\npipeline-1__Fare              0.414994\npipeline-2__Embarked_C        0.286461\npipeline-1__Parch             0.163889\n                                ...   \npipeline-2__Ticket_3101295   -0.093152\npipeline-2__Embarked_S       -0.244726\npipeline-2__Cabin_B96 B98    -0.460145\npipeline-1__Pclass           -0.472895\npipeline-2__Sex_male         -0.692025\nName: Survived, Length: 1732, dtype: float64"},"metadata":{}}]},{"cell_type":"code","source":"# Decision tree\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.metrics import accuracy_score, classification_report, confusion_matrix\nfrom sklearn.model_selection import RandomizedSearchCV\n\n# Define the hyperparameter grid\nparam_grid = {\n    'classifier__criterion': ['gini', 'entropy'],\n    'classifier__splitter': ['best', 'random'],\n    'classifier__max_depth': [None, 10, 20, 30, 40, 50],\n    'classifier__min_samples_split': [2, 5, 10],\n    'classifier__min_samples_leaf': [1, 2, 4],\n    'classifier__max_features': ['auto', 'sqrt', 'log2', None]\n}\n\n# Decision tree pipeline with RandomizedSearchCV\ntree_model = Pipeline([\n    (\"preprocessing\", preprocessing),\n    (\"classifier\", DecisionTreeClassifier(random_state=42))\n])\n\n# Set up RandomizedSearchCV on the pipeline\nrandom_search = RandomizedSearchCV(tree_model, param_distributions=param_grid, n_iter=100, scoring='accuracy', cv=5, n_jobs=-1, random_state=42)\n\n# Perform the search on the training data\nrandom_search.fit(X_train, y_train)\n\n# Get the best hyperparameters\nbest_params = random_search.best_params_\nprint(\"Best Hyperparameters:\", best_params)\n\n# Get the best model\nbest_tree_model = random_search.best_estimator_","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Best Hyperparameters: {'classifier__splitter': 'best', 'classifier__min_samples_split': 5, 'classifier__min_samples_leaf': 1, 'classifier__max_features': None, 'classifier__max_depth': 30, 'classifier__criterion': 'entropy'}","metadata":{}},{"cell_type":"code","source":"from sklearn.metrics import accuracy_score, classification_report, confusion_matrix, precision_score, recall_score, f1_score\n\n# Evaluate the best model on the test set\ny_pred = best_tree_model.predict(X_test)\n\n# Evaluate the Decision Tree model\naccuracy_tree = accuracy_score(y_test, y_pred)\nprint(f'Best Decision Tree Accuracy: {accuracy_tree:.2f}')\n\n# Display additional evaluation metrics\nprint(\"\\nClassification Report:\")\nprint(classification_report(y_test, y_pred))\n\n# Display the confusion matrix\nprint(\"\\nConfusion Matrix:\")\nprint(confusion_matrix(y_test, y_pred))\n\n# Additional metrics\nprecision = precision_score(y_test, y_pred)\nrecall = recall_score(y_test, y_pred)\nf1 = f1_score(y_test, y_pred)\n\n# Display additional metrics\nprint(\"\\nPrecision:\", precision)\nprint(\"Recall:\", recall)\nprint(\"F1 Score:\", f1)\n","metadata":{"execution":{"iopub.status.busy":"2023-11-17T17:55:54.973056Z","iopub.execute_input":"2023-11-17T17:55:54.973488Z","iopub.status.idle":"2023-11-17T17:55:55.016009Z","shell.execute_reply.started":"2023-11-17T17:55:54.973454Z","shell.execute_reply":"2023-11-17T17:55:55.014698Z"},"trusted":true},"execution_count":42,"outputs":[{"name":"stdout","text":"Best Decision Tree Accuracy: 0.84\n\nClassification Report:\n              precision    recall  f1-score   support\n\n           0       0.88      0.86      0.87       114\n           1       0.76      0.80      0.78        65\n\n    accuracy                           0.84       179\n   macro avg       0.82      0.83      0.83       179\nweighted avg       0.84      0.84      0.84       179\n\n\nConfusion Matrix:\n[[98 16]\n [13 52]]\n\nPrecision: 0.7647058823529411\nRecall: 0.8\nF1 Score: 0.7819548872180452\n","output_type":"stream"}]}]}